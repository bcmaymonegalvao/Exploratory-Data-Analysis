import streamlit as st
import pandas as pd
import numpy as np
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, roc_auc_score, confusion_matrix, 
                             classification_report, roc_curve, auc)
import matplotlib.pyplot as plt
import seaborn as sns

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Titanic Survival Predictor",
    page_icon="üö¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo do aplicativo
st.title("üö¢ Titanic Survival Prediction App")
st.markdown("""
Este aplicativo prev√™ a probabilidade de sobreviv√™ncia no Titanic usando Machine Learning.
Use as abas abaixo para explorar os dados, fazer previs√µes ou analisar as m√©tricas do modelo.
""")

# Carregar dados
@st.cache_data
def load_data():
    url = "https://raw.githubusercontent.com/bcmaymonegalvao/Exploratory-Data-Analysis/main/train.csv"
    data = pd.read_csv(url)
    return data

# Pr√©-processamento dos dados
@st.cache_data
def preprocess_data(data):
    # Fazer uma c√≥pia para n√£o modificar o original
    df = data.copy()
    
    # Preencher valores faltantes
    df['Age'] = df['Age'].fillna(df['Age'].median())
    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])
    df['Fare'] = df['Fare'].fillna(df['Fare'].median())
    
    # Feature engineering
    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1
    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)
    
    # Extrair t√≠tulos dos nomes
    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 
                                      'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')
    df['Title'] = df['Title'].replace('Mlle', 'Miss')
    df['Title'] = df['Title'].replace('Ms', 'Miss')
    df['Title'] = df['Title'].replace('Mme', 'Mrs')
    
    # Mapear categorias para valores num√©ricos
    label_encoders = {}
    categorical_cols = ['Sex', 'Embarked', 'Title']
    for col in categorical_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))
        label_encoders[col] = le
    
    return df, label_encoders

# Carregar modelo (se existir) ou treinar um novo
@st.cache_resource
def load_or_train_model(data):
    try:
        # Tentar carregar um modelo salvo
        with open('titanic_model.pkl', 'rb') as f:
            model = pickle.load(f)
        st.sidebar.success("Modelo carregado com sucesso!")
        
        # Carregar tamb√©m as m√©tricas salvas
        with open('titanic_metrics.pkl', 'rb') as f:
            metrics = pickle.load(f)
            
    except:
        st.sidebar.info("Treinando um novo modelo...")
        
        # Selecionar features para o modelo
        features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 
                   'Embarked', 'FamilySize', 'IsAlone', 'Title']
        
        X = data[features]
        y = data['Survived']
        
        # Dividir em treino e teste
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Treinar modelo
        model = RandomForestClassifier(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # Fazer previs√µes
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)
        
        # Calcular m√©tricas
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_pred_proba[:, 1])
        
        # Calcular matriz de confus√£o
        cm = confusion_matrix(y_test, y_pred)
        
        # Calcular curva ROC
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])
        roc_auc = auc(fpr, tpr)
        
        # Salvar m√©tricas
        metrics = {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'roc_auc': roc_auc,
            'confusion_matrix': cm,
            'fpr': fpr,
            'tpr': tpr,
            'classification_report': classification_report(y_test, y_pred, output_dict=True)
        }
        
        # Salvar modelo
        with open('titanic_model.pkl', 'wb') as f:
            pickle.dump(model, f)
        
        # Salvar m√©tricas
        with open('titanic_metrics.pkl', 'wb') as f:
            pickle.dump(metrics, f)
        
        st.sidebar.success("Novo modelo treinado e salvo com sucesso!")
    
    return model, metrics

# Carregar dados
df = load_data()
df_processed, label_encoders = preprocess_data(df)
model, metrics = load_or_train_model(df_processed)

# Sidebar para inputs do usu√°rio
st.sidebar.header("Filtros de Passageiro")

# Filtros para a base de dados
st.sidebar.subheader("Filtrar Base de Dados")
pclass_filter = st.sidebar.multiselect(
    "Classe", 
    options=[1, 2, 3], 
    default=[1, 2, 3],
    help="Filtrar por classe do passageiro"
)

sex_filter = st.sidebar.multiselect(
    "Sexo", 
    options=["Masculino", "Feminino"], 
    default=["Masculino", "Feminino"],
    help="Filtrar por sexo do passageiro"
)

age_range = st.sidebar.slider(
    "Faixa de Idade", 
    min_value=0, 
    max_value=100, 
    value=(0, 100),
    help="Selecionar faixa de idade"
)

# Mapear sexo para valores do dataframe
sex_map = {"Masculino": "male", "Feminino": "female"}
selected_sex = [sex_map[s] for s in sex_filter]

# Aplicar filtros
filtered_df = df[
    (df['Pclass'].isin(pclass_filter)) &
    (df['Sex'].isin(selected_sex)) &
    (df['Age'] >= age_range[0]) &
    (df['Age'] <= age_range[1])
]

# Criar abas
tab1, tab2, tab3 = st.tabs(["üìä An√°lise Explorat√≥ria", "üîÆ Previs√µes", "üìà M√©tricas do Modelo"])

# ABA 1: AN√ÅLISE EXPLORAT√ìRIA
with tab1:
    st.header("An√°lise Explorat√≥ria dos Dados do Titanic")
    
    # Estat√≠sticas descritivas
    st.subheader("Estat√≠sticas Descritivas")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total de Passageiros", len(filtered_df))
        st.metric("Sobreviventes", filtered_df['Survived'].sum())
    
    with col2:
        survival_rate = filtered_df['Survived'].mean() * 100 if len(filtered_df) > 0 else 0
        st.metric("Taxa de Sobreviv√™ncia", f"{survival_rate:.2f}%")
        avg_age = filtered_df['Age'].mean() if len(filtered_df) > 0 else 0
        st.metric("Idade M√©dia", f"{avg_age:.1f} anos")
    
    with col3:
        avg_fare = filtered_df['Fare'].mean() if len(filtered_df) > 0 else 0
        st.metric("Tarifa M√©dia", f"${avg_fare:.2f}")
        max_fare = filtered_df['Fare'].max() if len(filtered_df) > 0 else 0
        st.metric("Maior Tarifa", f"${max_fare:.2f}")
    
    # Gr√°ficos
    st.subheader("Visualiza√ß√µes dos Dados")
    
    # Sobreviv√™ncia por classe
    if not filtered_df.empty:
        fig, ax = plt.subplots(figsize=(10, 6))
        survival_by_class = pd.crosstab(filtered_df['Pclass'], filtered_df['Survived'])
        if not survival_by_class.empty:
            survival_by_class.plot(kind='bar', color=['#ffccc7', '#ff4d4f'], ax=ax)
            plt.title('Sobreviv√™ncia por Classe', fontsize=16)
            plt.xlabel('Classe', fontsize=12)
            plt.ylabel('N√∫mero de Passageiros', fontsize=12)
            plt.legend(['N√£o Sobreviveu', 'Sobreviveu'])
            st.pyplot(fig)
        else:
            st.warning("N√£o h√° dados para plotar o gr√°fico de sobreviv√™ncia por classe.")
        
        # Sobreviv√™ncia por sexo
        fig, ax = plt.subplots(figsize=(10, 6))
        survival_by_sex = pd.crosstab(filtered_df['Sex'], filtered_df['Survived'])
        if not survival_by_sex.empty:
            survival_by_sex.plot(kind='bar', color=['#ffccc7', '#ff4d4f'], ax=ax)
            plt.title('Sobreviv√™ncia por Sexo', fontsize=16)
            plt.xlabel('Sexo', fontsize=12)
            plt.ylabel('N√∫mero de Passageiros', fontsize=12)
            plt.legend(['N√£o Sobreviveu', 'Sobreviveu'])
            # Mapear os valores de sexo para os r√≥tulos
            ax.set_xticklabels(['Feminino', 'Masculino'], rotation=0)
            st.pyplot(fig)
        else:
            st.warning("N√£o h√° dados para plotar o gr√°fico de sobreviv√™ncia por sexo.")
        
        # Distribui√ß√£o de idades
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.histplot(data=filtered_df, x='Age', hue='Survived', multiple='stack', 
                     palette='YlOrRd', bins=20, ax=ax)
        plt.title('Distribui√ß√£o de Idades por Sobreviv√™ncia', fontsize=16)
        plt.xlabel('Idade', fontsize=12)
        plt.ylabel('N√∫mero de Passageiros', fontsize=12)
        st.pyplot(fig)
        
        # Distribui√ß√£o de tarifas
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.boxplot(data=filtered_df, x='Pclass', y='Fare', hue='Survived', palette='YlOrRd', ax=ax)
        plt.title('Distribui√ß√£o de Tarifas por Classe e Sobreviv√™ncia', fontsize=16)
        plt.xlabel('Classe', fontsize=12)
        plt.ylabel('Tarifa', fontsize=12)
        st.pyplot(fig)
        
        # Heatmap de correla√ß√£o
        st.subheader("Mapa de Calor de Correla√ß√µes")
        numeric_df = filtered_df.select_dtypes(include=[np.number])
        if not numeric_df.empty:
            fig, ax = plt.subplots(figsize=(10, 8))
            sns.heatmap(numeric_df.corr(), annot=True, cmap='YlOrRd', center=0, ax=ax)
            plt.title('Matriz de Correla√ß√£o', fontsize=16)
            st.pyplot(fig)
        else:
            st.warning("N√£o h√° dados num√©ricos para calcular correla√ß√µes.")
    else:
        st.warning("N√£o h√° dados para visualizar. Ajuste os filtros.")
    
    # Tabela de dados
    st.subheader("Visualiza√ß√£o dos Dados Filtrados")
    st.dataframe(filtered_df)

# ABA 2: PREVIS√ïES
with tab2:
    st.header("Previs√µes de Sobreviv√™ncia")
    
    # Op√ß√µes de previs√£o
    prediction_type = st.radio(
        "Tipo de Previs√£o:",
        ["Previs√£o Individual", "Previs√£o em Lote"],
        horizontal=True
    )
    
    if prediction_type == "Previs√£o Individual":
        st.subheader("Previs√£o Individual")
        
        # Inputs para previs√£o individual
        col1, col2 = st.columns(2)
        
        with col1:
            pclass = st.selectbox("Classe", [1, 2, 3], help="1 = Primeira, 2 = Segunda, 3 = Terceira")
            sex = st.selectbox("Sexo", ["Masculino", "Feminino"])
            age = st.slider("Idade", 0, 100, 30)
            sibsp = st.slider("N√∫mero de Irm√£os/C√¥njuges a bordo", 0, 8, 0)
        
        with col2:
            parch = st.slider("N√∫mero de Pais/Filhos a bordo", 0, 6, 0)
            fare = st.slider("Tarifa Paga", 0, 300, 30)
            embarked = st.selectbox("Porto de Embarque", ["Cherbourg", "Queenstown", "Southampton"])
        
        # Calcular caracter√≠sticas derivadas
        family_size = sibsp + parch + 1
        is_alone = 1 if family_size == 1 else 0
        
        # Converter entradas para formato do modelo
        sex_encoded = 1 if sex == "Masculino" else 0
        embarked_encoded = {"Cherbourg": 0, "Queenstown": 1, "Southampton": 2}[embarked]
        
        # Para t√≠tulo, usaremos "Mr" como padr√£o para homens e "Miss" para mulheres
        title = "Mr" if sex == "Masculino" else "Miss"
        title_encoded = 2 if title == "Mr" else 3  # Valores baseados no encoding feito durante o treino
        
        # Organizar dados em um DataFrame
        user_data = {
            'Pclass': pclass,
            'Sex': sex_encoded,
            'Age': age,
            'SibSp': sibsp,
            'Parch': parch,
            'Fare': fare,
            'Embarked': embarked_encoded,
            'FamilySize': family_size,
            'IsAlone': is_alone,
            'Title': title_encoded
        }
        
        features = pd.DataFrame(user_data, index=[0])
        
        # Fazer previs√£o
        prediction = model.predict(features)
        prediction_proba = model.predict_proba(features)
        
        # Mostrar resultados
        st.subheader("Resultado da Previs√£o")
        survival_status = "Sobreviveu" if prediction[0] == 1 else "N√£o Sobreviveu"
        survival_icon = "‚úÖ" if prediction[0] == 1 else "‚ùå"
        
        st.markdown(f"### {survival_icon} Previs√£o: {survival_status}")
        
        # Mostrar probabilidades
        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="Probabilidade de N√£o Sobreviv√™ncia", 
                      value=f"{prediction_proba[0][0]*100:.2f}%")
        with col2:
            st.metric(label="Probabilidade de Sobreviv√™ncia", 
                      value=f"{prediction_proba[0][1]*100:.2f}%")
        
        # Gr√°fico de probabilidades
        fig, ax = plt.subplots(figsize=(8, 4))
        ax.bar(['N√£o Sobreviveu', 'Sobreviveu'], prediction_proba[0], color=['#ffccc7', '#ff4d4f'])
        ax.set_ylabel('Probabilidade')
        ax.set_title('Probabilidade de Sobreviv√™ncia')
        st.pyplot(fig)
    
    else:
        st.subheader("Previs√£o em Lote")
        st.info("""
        Esta se√ß√£o faz previs√µes para todos os passageiros na base de dados filtrada.
        Use os filtros na barra lateral para ajustar o conjunto de dados.
        """)
        
        if filtered_df.empty:
            st.warning("N√£o h√° dados para fazer previs√µes em lote. Ajuste os filtros.")
        else:
            # Pr√©-processar dados filtrados para previs√£o
            filtered_processed, _ = preprocess_data(filtered_df)
            
            # Selecionar features para o modelo
            features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 
                       'Embarked', 'FamilySize', 'IsAlone', 'Title']
            
            X = filtered_processed[features]
            
            # Fazer previs√µes
            predictions = model.predict(X)
            predictions_proba = model.predict_proba(X)
            
            # Adicionar previs√µes ao DataFrame
            results_df = filtered_df.copy()
            results_df['Predicted_Survival'] = predictions
            results_df['Survival_Probability'] = predictions_proba[:, 1]
            
            # Estat√≠sticas das previs√µes
            st.subheader("Estat√≠sticas das Previs√µes")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Passageiros na Amostra", len(results_df))
                st.metric("Previs√£o de Sobreviventes", results_df['Predicted_Survival'].sum())
            
            with col2:
                predicted_survival_rate = results_df['Predicted_Survival'].mean() * 100
                st.metric("Taxa de Sobreviv√™ncia Prevista", f"{predicted_survival_rate:.2f}%")
                if 'Survived' in results_df:
                    actual_survival_rate = results_df['Survived'].mean() * 100
                    st.metric("Taxa de Sobreviv√™ncia Real", f"{actual_survival_rate:.2f}%")
                else:
                    st.metric("Taxa de Sobreviv√™ncia Real", "N/A")
            
            with col3:
                avg_prob = results_df['Survival_Probability'].mean()
                st.metric("Probabilidade M√©dia de Sobreviv√™ncia", f"{avg_prob*100:.2f}%")
            
            # Gr√°fico de distribui√ß√£o de probabilidades
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.histplot(data=results_df, x='Survival_Probability', hue='Predicted_Survival', 
                         multiple='stack', palette='YlOrRd', bins=20, ax=ax)
            plt.title('Distribui√ß√£o das Probabilidades de Sobreviv√™ncia', fontsize=16)
            plt.xlabel('Probabilidade de Sobreviv√™ncia', fontsize=12)
            plt.ylabel('N√∫mero de Passageiros', fontsize=12)
            st.pyplot(fig)
            
            # Gr√°fico de compara√ß√£o entre previs√µes e resultados real
            if 'Survived' in results_df:
                st.subheader("Compara√ß√£o entre Previs√µes e Resultados Reais")
                
                # Calcular acur√°cia
                accuracy = (results_df['Predicted_Survival'] == results_df['Survived']).mean()
                st.metric("Acur√°cia do Modelo", f"{accuracy*100:.2f}%")
                
                # Matriz de confus√£o
                from sklearn.metrics import confusion_matrix
                cm = confusion_matrix(results_df['Survived'], results_df['Predicted_Survival'])
                
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd', ax=ax,
                            xticklabels=['N√£o Sobreviveu', 'Sobreviveu'],
                            yticklabels=['N√£o Sobreviveu', 'Sobreviveu'])
                plt.title('Matriz de Confus√£o', fontsize=16)
                plt.ylabel('Real', fontsize=12)
                plt.xlabel('Previsto', fontsize=12)
                st.pyplot(fig)
            
            # Tabela com resultados
            st.subheader("Resultados das Previs√µes")
            st.dataframe(results_df[['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 
                                    'Survived', 'Predicted_Survival', 'Survival_Probability']].head(20))

# ABA 3: M√âTRICAS DO MODELO
with tab3:
    st.header("M√©tricas de Avalia√ß√£o do Modelo")
    
    # Introdu√ß√£o
    st.markdown("""
    ### Import√¢ncia das M√©tricas de Avalia√ß√£o
    
    As m√©tricas de avalia√ß√£o s√£o fundamentais para entender o desempenho de um modelo de machine learning.
    Cada m√©trica fornece uma perspectiva diferente sobre como o modelo est√° se saindo na tarefa de classifica√ß√£o.
    """)
    
    # M√©tricas principais
    st.subheader("M√©tricas Principais")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Acur√°cia", f"{metrics['accuracy']*100:.2f}%")
        with st.expander("O que √© Acur√°cia?"):
            st.markdown("""
            **Acur√°cia** mede a propor√ß√£o de previs√µes corretas (tanto positivas quanto negativas) em rela√ß√£o ao total de previs√µes.
            
            **F√≥rmula**: (Verdadeiros Positivos + Verdadeiros Negativos) / Total
            
            **Interpreta√ß√£o**: Uma acur√°cia de 80% significa que o modelo acertou 80% das previs√µes.
            
            **Limita√ß√£o**: Em conjuntos de dados desbalanceados, a acur√°cia pode ser enganosa.
            """)
    
    with col2:
        st.metric("Precis√£o", f"{metrics['precision']*100:.2f}%")
        with st.expander("O que √© Precis√£o?"):
            st.markdown("""
            **Precis√£o** mede a propor√ß√£o de verdadeiros positivos em rela√ß√£o a todos os casos classificados como positivos.
            
            **F√≥rmula**: Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos)
            
            **Interpreta√ß√£o**: Uma precis√£o de 75% significa que, das pessoas que o modelo previu como sobreviventes, 75% realmente sobreviveram.
            
            **Importante**: M√©trica crucial quando o custo dos falsos positivos √© alto.
            """)
    
    with col3:
        st.metric("Recall (Sensibilidade)", f"{metrics['recall']*100:.2f}%")
        with st.expander("O que √© Recall?"):
            st.markdown("""
            **Recall** (tamb√©m chamado de Sensibilidade) mede a propor√ß√£o de verdadeiros positivos em rela√ß√£o a todos os casos que s√£o realmente positivos.
            
            **F√≥rmula**: Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)
            
            **Interpreta√ß√£o**: Um recall de 70% significa que o modelo identificou corretamente 70% de todos os sobreviventes reais.
            
            **Importante**: M√©trica crucial quando o custo dos falsos negativos √© alto.
            """)
    
    with col4:
        st.metric("F1-Score", f"{metrics['f1']*100:.2f}%")
        with st.expander("O que √© F1-Score?"):
            st.markdown("""
            **F1-Score** √© a m√©dia harm√¥nica entre Precis√£o e Recall, proporcionando um equil√≠brio entre as duas m√©tricas.
            
            **F√≥rmula**: 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)
            
            **Interpreta√ß√£o**: Um F1-Score de 80% indica um bom equil√≠brio entre precis√£o e recall.
            
            **Importante**: M√©trica especialmente √∫til em conjuntos de dados desbalanceados.
            """)
    
    # Matriz de Confus√£o
    st.subheader("Matriz de Confus√£o")
    
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d', cmap='YlOrRd', ax=ax,
                xticklabels=['N√£o Sobreviveu', 'Sobreviveu'],
                yticklabels=['N√£o Sobreviveu', 'Sobreviveu'])
    plt.title('Matriz de Confus√£o', fontsize=16)
    plt.ylabel('Valor Real', fontsize=12)
    plt.xlabel('Previs√£o do Modelo', fontsize=12)
    st.pyplot(fig)
    
    with st.expander("O que √© a Matriz de Confus√£o?"):
        st.markdown("""
        A **Matriz de Confus√£o** √© uma tabela que mostra o desempenho de um modelo de classifica√ß√£o:
        
        - **Verdadeiros Negativos (TN)**: Casos negativos corretamente classificados como negativos
        - **Falsos Positivos (FP)**: Casos negativos incorretamente classificados como positivos (Erro Tipo I)
        - **Falsos Negativos (FN)**: Casos positivos incorretamente classificados como negativos (Erro Tipo II)
        - **Verdadeiros Positivos (TP)**: Casos positivos corretamente classificados como positivos
        
        A matriz de confus√£o permite calcular v√°rias m√©tricas de desempenho e entender os tipos de erros que o modelo est√° cometendo.
        """)
    
    # Curva ROC
    st.subheader("Curva ROC e √Årea sob a Curva (AUC)")
    
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.plot(metrics['fpr'], metrics['tpr'], color='darkorange', lw=2, 
            label=f'Curva ROC (AUC = {metrics["roc_auc"]:.2f})')
    ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Classificador Aleat√≥rio')
    ax.set_xlim([0.0, 1.0])
    ax.set_ylim([0.0, 1.05])
    ax.set_xlabel('Taxa de Falsos Positivos', fontsize=12)
    ax.set_ylabel('Taxa de Verdadeiros Positivos', fontsize=12)
    ax.set_title('Curva ROC', fontsize=16)
    ax.legend(loc="lower right")
    st.pyplot(fig)
    
    with st.expander("O que √© a Curva ROC e AUC?"):
        st.markdown("""
        A **Curva ROC (Receiver Operating Characteristic)** mostra o desempenho de um modelo de classifica√ß√£o em todos os limiares de classifica√ß√£o.
        
        - **Eixo X**: Taxa de Falsos Positivos (FPR) - propor√ß√£o de negativos classificados incorretamente como positivos
        - **Eixo Y**: Taxa de Verdadeiros Positivos (TPR) - tamb√©m conhecida como Recall ou Sensibilidade
        
        **AUC (√Årea sob a Curva)** quantifica a capacidade do modelo de distinguir entre classes:
        
        - **AUC = 0.5**: O modelo n√£o √© melhor que um classificador aleat√≥rio
        - **AUC = 1.0**: Classifica√ß√£o perfeita
        - **AUC entre 0.5 e 1.0**: Quanto maior, melhor a capacidade do modelo de distinguir entre classes
        
        Um AUC de {:.2f} indica que o modelo tem {} de capacidade de distinguir entre sobreviventes e n√£o-sobreviventes.
        """.format(metrics['roc_auc'], "excelente" if metrics['roc_auc'] > 0.9 else "boa" if metrics['roc_auc'] > 0.8 else "moderada"))
    
    # Relat√≥rio de Classifica√ß√£o
    st.subheader("Relat√≥rio de Classifica√ß√£o Detalhado")
    
    # Converter o relat√≥rio de classifica√ß√£o para DataFrame
    report_df = pd.DataFrame(metrics['classification_report']).transpose()
    st.dataframe(report_df.style.format('{:.2f}'))
    
    with st.expander("Entendendo o Relat√≥rio de Classifica√ß√£o"):
        st.markdown("""
        O **Relat√≥rio de Classifica√ß√£o** fornece m√©tricas detalhadas para cada classe:
        
        - **Precision**: Propor√ß√£o de previs√µes corretas para esta classe
        - **Recall**: Propor√ß√£o de casos reais desta classe que foram corretamente identificados
        - **F1-score**: M√©dia harm√¥nica entre Precision e Recall
        - **Support**: N√∫mero de ocorr√™ncias reais desta classe no conjunto de teste
        
        As m√©tricas s√£o calculadas para cada classe (0 = N√£o Sobreviveu, 1 = Sobreviveu) e tamb√©m fornecidas como m√©dias:
        
        - **Macro avg**: M√©dia simples das m√©tricas por classe
        - **Weighted avg**: M√©dia ponderada pelas ocorr√™ncias de cada classe
        """)
    
    # An√°lise de Import√¢ncia de Features
    st.subheader("Import√¢ncia das Caracter√≠sticas (Features)")
    
    feature_importance = model.feature_importances_
    feature_names = ['Classe', 'Sexo', 'Idade', 'Irm√£os/C√¥njuges', 'Pais/Filhos', 
                     'Tarifa', 'Porto', 'Tamanho Fam√≠lia', 'Sozinho', 'T√≠tulo']
    
    # Criar DataFrame para import√¢ncia das features
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': feature_importance
    }).sort_values('Importance', ascending=True)
    
    # Gr√°fico de import√¢ncia
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.barh(importance_df['Feature'], importance_df['Importance'], color='#ff7f0e')
    ax.set_xlabel('Import√¢ncia', fontsize=12)
    ax.set_title('Import√¢ncia das Caracter√≠sticas no Modelo', fontsize=16)
    st.pyplot(fig)
    
    with st.expander("O que √© Import√¢ncia de Features?"):
        st.markdown("""
        A **Import√¢ncia de Features** indica o quanto cada caracter√≠stica contribui para as previs√µes do modelo.
        
        No algoritmo Random Forest, a import√¢ncia √© calculada com base em:
        
        1. **Diminui√ß√£o da Impureza**: Quanto cada feature reduz a impureza (Gini ou entropia) nas √°rvores
        2. **Frequ√™ncia de Uso**: Com que frequ√™ncia cada feature √© usada para dividir os dados
        
        **Interpreta√ß√£o**: Features com maior import√¢ncia t√™m mais influ√™ncia nas previs√µes do modelo.
        
        No nosso caso, as caracter√≠sticas mais importantes para prever a sobreviv√™ncia no Titanic s√£o:
        {}
        """.format(", ".join(importance_df.nlargest(3, 'Importance')['Feature'].tolist())))

# Informa√ß√µes sobre o modelo
st.sidebar.header("Sobre o Modelo")
st.sidebar.info("""
Este modelo utiliza um algoritmo Random Forest Classifier
treinado nos dados dos passageiros do Titanic.

**Accuracy:** ~82% (valida√ß√£o cruzada)
**Features utilizadas:**
- Classe, Sexo, Idade
- N√∫mero de familiares
- Tarifa paga
- Porto de embarque
- T√≠tulo (extra√≠do do nome)
""")

# Rodap√©
st.markdown("---")
st.markdown("""
**Desenvolvido por Bruno Galv√£o**  
Baseado na an√°lise explorat√≥ria de dados do Titanic:  
[GitHub Repository](https://github.com/bcmaymonegalvao/Exploratory-Data-Analysis)
""")
